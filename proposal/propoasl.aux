\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nty/global//global/global/global}
\abx@aux@cite{0}{strassen1969gaussian}
\abx@aux@segm{0}{0}{strassen1969gaussian}
\abx@aux@cite{0}{coppersmith1990matrix}
\abx@aux@segm{0}{0}{coppersmith1990matrix}
\abx@aux@cite{0}{fawzi2022discovering}
\abx@aux@segm{0}{0}{fawzi2022discovering}
\abx@aux@cite{0}{strassen1969gaussian}
\abx@aux@segm{0}{0}{strassen1969gaussian}
\abx@aux@cite{0}{coppersmith1990matrix}
\abx@aux@segm{0}{0}{coppersmith1990matrix}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Tensor representation of matrix multiplication as a rank-3 tensor. Lower-rank decompositions reduce scalar multiplications. (Source: AlphaTensor paper)}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:tensor-representation}{{1}{1}{Tensor representation of matrix multiplication as a rank-3 tensor. Lower-rank decompositions reduce scalar multiplications. (Source: AlphaTensor paper)}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{1}{section.2}\protected@file@percent }
\abx@aux@cite{0}{fawzi2022discovering}
\abx@aux@segm{0}{0}{fawzi2022discovering}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{2}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces AlphaTensor's reinforcement learning framework for algorithm discovery. (Source: AlphaTensor paper)}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:alphatensor-framework}{{2}{2}{AlphaTensor's reinforcement learning framework for algorithm discovery. (Source: AlphaTensor paper)}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Speed ups of the AlphaTensor-discovered algorithm (Source: AlphaTensor paper)}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:speedups-alphatensor}{{3}{3}{Speed ups of the AlphaTensor-discovered algorithm (Source: AlphaTensor paper)}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Contribution}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Expected Results and Analysis}{4}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison between the complexity of previous known matrix multiplication algorithms and the ones discovered by AlphaTensor. (Source: AlphaTensor paper)}}{5}{figure.4}\protected@file@percent }
\newlabel{fig:comparison-alphatensor}{{4}{5}{Comparison between the complexity of previous known matrix multiplication algorithms and the ones discovered by AlphaTensor. (Source: AlphaTensor paper)}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Algorithm discovery beyond standard matrix multiplication (Source: AlphaTensor paper)}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:standard-matrix}{{5}{5}{Algorithm discovery beyond standard matrix multiplication (Source: AlphaTensor paper)}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{6}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{6}{section.7}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{B88AB88B71F68A8DF3FC1A496CDED1C4}
\abx@aux@defaultrefcontext{0}{coppersmith1990matrix}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{fawzi2022discovering}{nty/global//global/global/global}
\abx@aux@defaultrefcontext{0}{strassen1969gaussian}{nty/global//global/global/global}
\gdef \@abspage@last{6}
